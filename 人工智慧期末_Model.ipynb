{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vuRBqmq_okIo",
    "outputId": "a9d89cda-f924-4af4-b47e-efb5afc8910e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.20.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "NZ-yp2YwnQw1",
    "outputId": "740386a3-772d-4856-cb26-522c3611d0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "#coding:utf-8\n",
    "import os\n",
    "\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2Ll94U-TnnwN",
    "outputId": "19d00089-547b-4311-a31f-f8a67a04cd6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model1.h5  test_fake_news.csv   人工智慧期末.ipynb\n",
      "my_model.h5   train_fake_news.csv\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/content/drive/My Drive/Colab/人工智慧期末')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "FTHwWYJjpo_s",
    "outputId": "fc92fba3-623e-47cc-e6c8-71c66af55593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5200 entries, 0 to 5199\n",
      "Data columns (total 4 columns):\n",
      "id        5200 non-null int64\n",
      "title     5078 non-null object\n",
      "author    4697 non-null object\n",
      "text      5193 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 162.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      "id        20800 non-null int64\n",
      "title     20242 non-null object\n",
      "author    18843 non-null object\n",
      "text      20761 non-null object\n",
      "label     20800 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#1: unreliable\n",
    "#0: reliable\n",
    "train=pd.read_csv('train_fake_news.csv')\n",
    "test=pd.read_csv('test_fake_news.csv')\n",
    "test.info()\n",
    "test['label']='t'\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "id": "9-UDHtTnmGCd",
    "outputId": "8453d468-90ac-4e71-9f4d-ee3769e0846d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
       "      <td>Megan Twohey and Scott Shane</td>\n",
       "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Obama’s Organizing for Action Partners with So...</td>\n",
       "      <td>Aaron Klein</td>\n",
       "      <td>Organizing for Action, the activist group that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...</td>\n",
       "      <td>Chris Tomlinson</td>\n",
       "      <td>The BBC produced spoof on the “Real Housewives...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Russian Researchers Discover Secret Nazi Milit...</td>\n",
       "      <td>Amando Flavio</td>\n",
       "      <td>The mystery surrounding The Third Reich and Na...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>US Officials See No Link Between Trump and Russia</td>\n",
       "      <td>Jason Ditz</td>\n",
       "      <td>Clinton Campaign Demands FBI Affirm Trump's Ru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Re: Yes, There Are Paid Government Trolls On S...</td>\n",
       "      <td>AnotherAnnie</td>\n",
       "      <td>Yes, There Are Paid Government Trolls On Socia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>In Major League Soccer, Argentines Find a Home...</td>\n",
       "      <td>Jack Williams</td>\n",
       "      <td>Guillermo Barros Schelotto was not the first A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Wells Fargo Chief Abruptly Steps Down - The Ne...</td>\n",
       "      <td>Michael Corkery and Stacy Cowley</td>\n",
       "      <td>The scandal engulfing Wells Fargo toppled its ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Anonymous Donor Pays $2.5 Million To Release E...</td>\n",
       "      <td>Starkman</td>\n",
       "      <td>A Caddo Nation tribal leader has just been fre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>FBI Closes In On Hillary!</td>\n",
       "      <td>The Doc</td>\n",
       "      <td>FBI Closes In On Hillary! Posted on Home » Hea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Chuck Todd: ’BuzzFeed Did Donald Trump a Polit...</td>\n",
       "      <td>Jeff Poor</td>\n",
       "      <td>Wednesday after   Donald Trump’s press confere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>News: Hope For The GOP: A Nude Paul Ryan Has J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Email \\nSince Donald Trump entered the electio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Monica Lewinsky, Clinton Sex Scandal Set for ’...</td>\n",
       "      <td>Jerome Hudson</td>\n",
       "      <td>Screenwriter Ryan Murphy, who has produced the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Rob Reiner: Trump Is ’Mentally Unstable’ - Bre...</td>\n",
       "      <td>Pam Key</td>\n",
       "      <td>Sunday on MSNBC’s “AM Joy,” actor and director...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Massachusetts Cop’s Wife Busted for Pinning Fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts Cop’s Wife Busted for Pinning Fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Abortion Pill Orders Rise in 7 Latin American ...</td>\n",
       "      <td>Donald G. McNeil Jr. and Pam Belluck</td>\n",
       "      <td>Orders for abortion pills by women in seven La...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Nukes and the UN: a Historic Treaty to Ban Nuc...</td>\n",
       "      <td>Ira Helfand</td>\n",
       "      <td>Email \\nIn an historic move the United Nations...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>EXCLUSIVE: Islamic State Supporters Vow to ‘Sh...</td>\n",
       "      <td>Aaron Klein and Ali Waked</td>\n",
       "      <td>JERUSALEM  —   Islamic State sympathizers and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Humiliated Hillary Tries To Hide What Camera C...</td>\n",
       "      <td>Amanda Shea</td>\n",
       "      <td>Humiliated Hillary Tries To Hide What Camera C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Andrea Tantaros of Fox News Claims Retaliation...</td>\n",
       "      <td>Jim Dwyer</td>\n",
       "      <td>Andrea Tantaros, a former Fox News host, charg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>How Hillary Clinton Became a Hawk - The New Yo...</td>\n",
       "      <td>Mark Landler</td>\n",
       "      <td>Hillary Clinton sat in the hideaway study off ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20770</th>\n",
       "      <td>20770</td>\n",
       "      <td>HUMA ABEDIN SWORE UNDER OATH SHE GAVE UP ‘ALL ...</td>\n",
       "      <td>Iron Sheik</td>\n",
       "      <td>Home › POLITICS | US NEWS › HUMA ABEDIN SWORE ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20771</th>\n",
       "      <td>20771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Letsbereal</td>\n",
       "      <td>DYN's Statement on Last Week's Botnet Attack h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20772</th>\n",
       "      <td>20772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beersession</td>\n",
       "      <td>Kinda reminds me of when Carter gave away the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20773</th>\n",
       "      <td>20773</td>\n",
       "      <td>Australia to hunt down anti-vax nurses and pro...</td>\n",
       "      <td>Vicki Batts</td>\n",
       "      <td>Australia to hunt down anti-vax nurses and pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20774</th>\n",
       "      <td>20774</td>\n",
       "      <td>Government Report: Islamists Building ’Paralle...</td>\n",
       "      <td>Liam Deacon</td>\n",
       "      <td>Aided by a politically correct culture of “tol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20775</th>\n",
       "      <td>20775</td>\n",
       "      <td>How this WWII airman is helping veterans heal ...</td>\n",
       "      <td>Arnaldo Rodgers</td>\n",
       "      <td>‹ › Arnaldo Rodgers is a trained and educated ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20776</th>\n",
       "      <td>20776</td>\n",
       "      <td>Trump Campaign Says Hillary Supporter Tried As...</td>\n",
       "      <td>Jameson Parker</td>\n",
       "      <td>Donald Trump was rushed from a rally stage by ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20777</th>\n",
       "      <td>20777</td>\n",
       "      <td>Editor of Austria’s Largest Paper Charged with...</td>\n",
       "      <td>admin</td>\n",
       "      <td>Breitbart October 26, 2016 \\nAn editor of Aust...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20778</th>\n",
       "      <td>20778</td>\n",
       "      <td>This Is a Jobs Report That Democrats Can Boast...</td>\n",
       "      <td>Neil Irwin</td>\n",
       "      <td>There’s not much to say about the July jobs nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20779</th>\n",
       "      <td>20779</td>\n",
       "      <td>Christians in 2017 ’Most Persecuted Group in t...</td>\n",
       "      <td>Thomas D. Williams, Ph.D.</td>\n",
       "      <td>In many parts of the world, Christians gatheri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20780</th>\n",
       "      <td>20780</td>\n",
       "      <td>Florida Woman Charged in Death of Infant in ‘C...</td>\n",
       "      <td>Christine Hauser</td>\n",
       "      <td>Early on Oct. 6, Erin   was awakened by the so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20781</th>\n",
       "      <td>20781</td>\n",
       "      <td>Time is Running Out to Stop Kratom Ban – Need ...</td>\n",
       "      <td>Heather Callaghan</td>\n",
       "      <td>By Brandon Turbeville When the DEA announced t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20782</th>\n",
       "      <td>20782</td>\n",
       "      <td>The Fix Is In: NBC Affiliate Accidentally Post...</td>\n",
       "      <td>The Doc</td>\n",
       "      <td>Home » Headlines » World News » The Fix Is In:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20783</th>\n",
       "      <td>20783</td>\n",
       "      <td>Samsung, Kim Jong-un, Rex Tillerson: Your Morn...</td>\n",
       "      <td>Charles McDermid</td>\n",
       "      <td>Good morning.  Here’s what you need to know: •...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20784</th>\n",
       "      <td>20784</td>\n",
       "      <td>Comment on World Heaves Sigh of Relief after T...</td>\n",
       "      <td>Debbie Menon</td>\n",
       "      <td>Finian Cunningham has written extensively on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20785</th>\n",
       "      <td>20785</td>\n",
       "      <td>Ann Coulter: How to Provide Universal Health C...</td>\n",
       "      <td>Ann Coulter</td>\n",
       "      <td>The first sentence of Congress’ Obamacare repe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20786</th>\n",
       "      <td>20786</td>\n",
       "      <td>Government Forces Advancing at Damascus-Aleppo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#FROMTHEFRONT #MAPS 22.11.2016 - 1,361 views 5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20787</th>\n",
       "      <td>20787</td>\n",
       "      <td>Sally Yates Won’t Say If Trump Was Wiretapped ...</td>\n",
       "      <td>Ian Mason</td>\n",
       "      <td>Former Deputy Attorney General Sally Yates dec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20788</th>\n",
       "      <td>20788</td>\n",
       "      <td>Maine’s Gov. LePage Threatens To ‘Investigate’...</td>\n",
       "      <td>Joe Clark</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20789</th>\n",
       "      <td>20789</td>\n",
       "      <td>Sen. McConnell: The Supreme Court Vacancy Was ...</td>\n",
       "      <td>Warner Todd Huston</td>\n",
       "      <td>Senate Majority Leader Mitch McConnell (R, KY)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20790</th>\n",
       "      <td>20790</td>\n",
       "      <td>Nikki Haley Blasts U.N. Human Rights Office fo...</td>\n",
       "      <td>Adam Shaw</td>\n",
       "      <td>U. S Ambassador to the United Nations Nikki Ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20791</th>\n",
       "      <td>20791</td>\n",
       "      <td>Lawyer Who Kept Hillary Campaign Chief Out of ...</td>\n",
       "      <td>Daniel Greenfield</td>\n",
       "      <td>Lawyer Who Kept Hillary Campaign Chief Out of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20792</th>\n",
       "      <td>20792</td>\n",
       "      <td>Jakarta Bombing Kills Three Police Officers, L...</td>\n",
       "      <td>John Hayward</td>\n",
       "      <td>Two suicide bombers attacked a bus station in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20793</th>\n",
       "      <td>20793</td>\n",
       "      <td>Idiot Who Destroyed Trump Hollywood Star Gets ...</td>\n",
       "      <td>Robert Rich</td>\n",
       "      <td>Share This \\nAlthough the vandal who thought i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20794</th>\n",
       "      <td>20794</td>\n",
       "      <td>Trump: Putin ’Very Smart’ to Not Retaliate ove...</td>\n",
       "      <td>Lee Stranahan</td>\n",
       "      <td>Donald Trump took to Twitter Friday to praise ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20795</th>\n",
       "      <td>20795</td>\n",
       "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
       "      <td>Jerome Hudson</td>\n",
       "      <td>Rapper T. I. unloaded on black celebrities who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20796</th>\n",
       "      <td>20796</td>\n",
       "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
       "      <td>Benjamin Hoffman</td>\n",
       "      <td>When the Green Bay Packers lost to the Washing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20797</th>\n",
       "      <td>20797</td>\n",
       "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
       "      <td>Michael J. de la Merced and Rachel Abrams</td>\n",
       "      <td>The Macy’s of today grew from the union of sev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20798</th>\n",
       "      <td>20798</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>Alex Ansary</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799</th>\n",
       "      <td>20799</td>\n",
       "      <td>What Keeps the F-35 Alive</td>\n",
       "      <td>David Swanson</td>\n",
       "      <td>David Swanson is an author, activist, journa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2          2                  Why the Truth Might Get You Fired   \n",
       "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4          4  Iranian woman jailed for fictional unpublished...   \n",
       "5          5  Jackie Mason: Hollywood Would Love Trump if He...   \n",
       "6          6  Life: Life Of Luxury: Elton John’s 6 Favorite ...   \n",
       "7          7  Benoît Hamon Wins French Socialist Party’s Pre...   \n",
       "8          8  Excerpts From a Draft Script for Donald Trump’...   \n",
       "9          9  A Back-Channel Plan for Ukraine and Russia, Co...   \n",
       "10        10  Obama’s Organizing for Action Partners with So...   \n",
       "11        11  BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...   \n",
       "12        12  Russian Researchers Discover Secret Nazi Milit...   \n",
       "13        13  US Officials See No Link Between Trump and Russia   \n",
       "14        14  Re: Yes, There Are Paid Government Trolls On S...   \n",
       "15        15  In Major League Soccer, Argentines Find a Home...   \n",
       "16        16  Wells Fargo Chief Abruptly Steps Down - The Ne...   \n",
       "17        17  Anonymous Donor Pays $2.5 Million To Release E...   \n",
       "18        18                          FBI Closes In On Hillary!   \n",
       "19        19  Chuck Todd: ’BuzzFeed Did Donald Trump a Polit...   \n",
       "20        20  News: Hope For The GOP: A Nude Paul Ryan Has J...   \n",
       "21        21  Monica Lewinsky, Clinton Sex Scandal Set for ’...   \n",
       "22        22  Rob Reiner: Trump Is ’Mentally Unstable’ - Bre...   \n",
       "23        23  Massachusetts Cop’s Wife Busted for Pinning Fa...   \n",
       "24        24  Abortion Pill Orders Rise in 7 Latin American ...   \n",
       "25        25  Nukes and the UN: a Historic Treaty to Ban Nuc...   \n",
       "26        26  EXCLUSIVE: Islamic State Supporters Vow to ‘Sh...   \n",
       "27        27  Humiliated Hillary Tries To Hide What Camera C...   \n",
       "28        28  Andrea Tantaros of Fox News Claims Retaliation...   \n",
       "29        29  How Hillary Clinton Became a Hawk - The New Yo...   \n",
       "...      ...                                                ...   \n",
       "20770  20770  HUMA ABEDIN SWORE UNDER OATH SHE GAVE UP ‘ALL ...   \n",
       "20771  20771                                                NaN   \n",
       "20772  20772                                                NaN   \n",
       "20773  20773  Australia to hunt down anti-vax nurses and pro...   \n",
       "20774  20774  Government Report: Islamists Building ’Paralle...   \n",
       "20775  20775  How this WWII airman is helping veterans heal ...   \n",
       "20776  20776  Trump Campaign Says Hillary Supporter Tried As...   \n",
       "20777  20777  Editor of Austria’s Largest Paper Charged with...   \n",
       "20778  20778  This Is a Jobs Report That Democrats Can Boast...   \n",
       "20779  20779  Christians in 2017 ’Most Persecuted Group in t...   \n",
       "20780  20780  Florida Woman Charged in Death of Infant in ‘C...   \n",
       "20781  20781  Time is Running Out to Stop Kratom Ban – Need ...   \n",
       "20782  20782  The Fix Is In: NBC Affiliate Accidentally Post...   \n",
       "20783  20783  Samsung, Kim Jong-un, Rex Tillerson: Your Morn...   \n",
       "20784  20784  Comment on World Heaves Sigh of Relief after T...   \n",
       "20785  20785  Ann Coulter: How to Provide Universal Health C...   \n",
       "20786  20786  Government Forces Advancing at Damascus-Aleppo...   \n",
       "20787  20787  Sally Yates Won’t Say If Trump Was Wiretapped ...   \n",
       "20788  20788  Maine’s Gov. LePage Threatens To ‘Investigate’...   \n",
       "20789  20789  Sen. McConnell: The Supreme Court Vacancy Was ...   \n",
       "20790  20790  Nikki Haley Blasts U.N. Human Rights Office fo...   \n",
       "20791  20791  Lawyer Who Kept Hillary Campaign Chief Out of ...   \n",
       "20792  20792  Jakarta Bombing Kills Three Police Officers, L...   \n",
       "20793  20793  Idiot Who Destroyed Trump Hollywood Star Gets ...   \n",
       "20794  20794  Trump: Putin ’Very Smart’ to Not Retaliate ove...   \n",
       "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
       "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
       "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
       "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
       "20799  20799                          What Keeps the F-35 Alive   \n",
       "\n",
       "                                          author  \\\n",
       "0                                  Darrell Lucus   \n",
       "1                                Daniel J. Flynn   \n",
       "2                             Consortiumnews.com   \n",
       "3                                Jessica Purkiss   \n",
       "4                                 Howard Portnoy   \n",
       "5                                Daniel Nussbaum   \n",
       "6                                            NaN   \n",
       "7                                Alissa J. Rubin   \n",
       "8                                            NaN   \n",
       "9                   Megan Twohey and Scott Shane   \n",
       "10                                   Aaron Klein   \n",
       "11                               Chris Tomlinson   \n",
       "12                                 Amando Flavio   \n",
       "13                                    Jason Ditz   \n",
       "14                                  AnotherAnnie   \n",
       "15                                 Jack Williams   \n",
       "16              Michael Corkery and Stacy Cowley   \n",
       "17                                      Starkman   \n",
       "18                                       The Doc   \n",
       "19                                     Jeff Poor   \n",
       "20                                           NaN   \n",
       "21                                 Jerome Hudson   \n",
       "22                                       Pam Key   \n",
       "23                                           NaN   \n",
       "24          Donald G. McNeil Jr. and Pam Belluck   \n",
       "25                                   Ira Helfand   \n",
       "26                     Aaron Klein and Ali Waked   \n",
       "27                                   Amanda Shea   \n",
       "28                                     Jim Dwyer   \n",
       "29                                  Mark Landler   \n",
       "...                                          ...   \n",
       "20770                                 Iron Sheik   \n",
       "20771                                 Letsbereal   \n",
       "20772                                beersession   \n",
       "20773                                Vicki Batts   \n",
       "20774                                Liam Deacon   \n",
       "20775                            Arnaldo Rodgers   \n",
       "20776                             Jameson Parker   \n",
       "20777                                      admin   \n",
       "20778                                 Neil Irwin   \n",
       "20779                  Thomas D. Williams, Ph.D.   \n",
       "20780                           Christine Hauser   \n",
       "20781                          Heather Callaghan   \n",
       "20782                                    The Doc   \n",
       "20783                           Charles McDermid   \n",
       "20784                               Debbie Menon   \n",
       "20785                                Ann Coulter   \n",
       "20786                                        NaN   \n",
       "20787                                  Ian Mason   \n",
       "20788                                  Joe Clark   \n",
       "20789                         Warner Todd Huston   \n",
       "20790                                  Adam Shaw   \n",
       "20791                          Daniel Greenfield   \n",
       "20792                               John Hayward   \n",
       "20793                                Robert Rich   \n",
       "20794                              Lee Stranahan   \n",
       "20795                              Jerome Hudson   \n",
       "20796                           Benjamin Hoffman   \n",
       "20797  Michael J. de la Merced and Rachel Abrams   \n",
       "20798                                Alex Ansary   \n",
       "20799                              David Swanson   \n",
       "\n",
       "                                                    text  label  \n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1      Ever get the feeling your life circles the rou...      0  \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "5      In these trying times, Jackie Mason is the Voi...      0  \n",
       "6      Ever wonder how Britain’s most iconic pop pian...      1  \n",
       "7      PARIS  —   France chose an idealistic, traditi...      0  \n",
       "8      Donald J. Trump is scheduled to make a highly ...      0  \n",
       "9      A week before Michael T. Flynn resigned as nat...      0  \n",
       "10     Organizing for Action, the activist group that...      0  \n",
       "11     The BBC produced spoof on the “Real Housewives...      0  \n",
       "12     The mystery surrounding The Third Reich and Na...      1  \n",
       "13     Clinton Campaign Demands FBI Affirm Trump's Ru...      1  \n",
       "14     Yes, There Are Paid Government Trolls On Socia...      1  \n",
       "15     Guillermo Barros Schelotto was not the first A...      0  \n",
       "16     The scandal engulfing Wells Fargo toppled its ...      0  \n",
       "17     A Caddo Nation tribal leader has just been fre...      1  \n",
       "18     FBI Closes In On Hillary! Posted on Home » Hea...      1  \n",
       "19     Wednesday after   Donald Trump’s press confere...      0  \n",
       "20     Email \\nSince Donald Trump entered the electio...      1  \n",
       "21     Screenwriter Ryan Murphy, who has produced the...      0  \n",
       "22     Sunday on MSNBC’s “AM Joy,” actor and director...      0  \n",
       "23     Massachusetts Cop’s Wife Busted for Pinning Fa...      1  \n",
       "24     Orders for abortion pills by women in seven La...      0  \n",
       "25     Email \\nIn an historic move the United Nations...      1  \n",
       "26     JERUSALEM  —   Islamic State sympathizers and ...      0  \n",
       "27     Humiliated Hillary Tries To Hide What Camera C...      1  \n",
       "28     Andrea Tantaros, a former Fox News host, charg...      0  \n",
       "29     Hillary Clinton sat in the hideaway study off ...      0  \n",
       "...                                                  ...    ...  \n",
       "20770  Home › POLITICS | US NEWS › HUMA ABEDIN SWORE ...      1  \n",
       "20771  DYN's Statement on Last Week's Botnet Attack h...      1  \n",
       "20772  Kinda reminds me of when Carter gave away the ...      1  \n",
       "20773  Australia to hunt down anti-vax nurses and pro...      1  \n",
       "20774  Aided by a politically correct culture of “tol...      0  \n",
       "20775  ‹ › Arnaldo Rodgers is a trained and educated ...      1  \n",
       "20776  Donald Trump was rushed from a rally stage by ...      1  \n",
       "20777  Breitbart October 26, 2016 \\nAn editor of Aust...      1  \n",
       "20778  There’s not much to say about the July jobs nu...      0  \n",
       "20779  In many parts of the world, Christians gatheri...      0  \n",
       "20780  Early on Oct. 6, Erin   was awakened by the so...      0  \n",
       "20781  By Brandon Turbeville When the DEA announced t...      1  \n",
       "20782  Home » Headlines » World News » The Fix Is In:...      1  \n",
       "20783  Good morning.  Here’s what you need to know: •...      0  \n",
       "20784    Finian Cunningham has written extensively on...      1  \n",
       "20785  The first sentence of Congress’ Obamacare repe...      0  \n",
       "20786  #FROMTHEFRONT #MAPS 22.11.2016 - 1,361 views 5...      1  \n",
       "20787  Former Deputy Attorney General Sally Yates dec...      0  \n",
       "20788  Google Pinterest Digg Linkedin Reddit Stumbleu...      1  \n",
       "20789  Senate Majority Leader Mitch McConnell (R, KY)...      0  \n",
       "20790  U. S Ambassador to the United Nations Nikki Ha...      0  \n",
       "20791  Lawyer Who Kept Hillary Campaign Chief Out of ...      1  \n",
       "20792  Two suicide bombers attacked a bus station in ...      0  \n",
       "20793  Share This \\nAlthough the vandal who thought i...      1  \n",
       "20794  Donald Trump took to Twitter Friday to praise ...      0  \n",
       "20795  Rapper T. I. unloaded on black celebrities who...      0  \n",
       "20796  When the Green Bay Packers lost to the Washing...      0  \n",
       "20797  The Macy’s of today grew from the union of sev...      0  \n",
       "20798  NATO, Russia To Hold Parallel Exercises In Bal...      1  \n",
       "20799    David Swanson is an author, activist, journa...      1  \n",
       "\n",
       "[20800 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ZcRSdk-9pdIt",
    "outputId": "fce5048b-4a0b-40f2-cc5a-e4323e2ce514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "Accuracy of ExtrTrees classifier on training set: 1.00\n",
      "Accuracy of Extratrees classifier on test set: 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data prep\n",
    "test=test.fillna(' ')\n",
    "train=train.fillna(' ')\n",
    "test['total']=test['title']+' '+test['author']+test['text']\n",
    "train['total']=train['title']+' '+train['author']+train['text']\n",
    "\n",
    "#tfidf\n",
    "#transformer = TfidfTransformer(smooth_idf=False)\n",
    "#count_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "#counts = count_vectorizer.fit_transform(train['total'].values)\n",
    "#tfidf = transformer.fit_transform(counts)\n",
    "tfidf = vect.transform(train['total'].values)\n",
    "\n",
    "targets = train['label'].values\n",
    "test_counts = vect.transform(test['total'].values)\n",
    "#test_counts = transformer.fit_transform(test_counts)\n",
    "\n",
    "#split in samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, targets, random_state=0)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n",
    "                              AdaBoostClassifier)\n",
    "\n",
    "Extr = ExtraTreesClassifier(n_estimators=5,n_jobs=4)\n",
    "clf = Extr.fit(X_train, y_train)\n",
    "print('Accuracy of ExtrTrees classifier on training set: {:.2f}'\n",
    "     .format(Extr.score(X_train, y_train)))\n",
    "print('Accuracy of Extratrees classifier on test set: {:.2f}'\n",
    "     .format(Extr.score(X_test, y_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "RGdNuVkepdLF",
    "outputId": "5f85ce06-2970-4474-f0f6-644e41caae23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Lasso classifier on training set: 1.00\n",
      "Accuracy of Lasso classifier on test set: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      2564\n",
      "           1       0.96      0.98      0.97      2636\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5200\n",
      "   macro avg       0.97      0.97      0.97      5200\n",
      "weighted avg       0.97      0.97      0.97      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "clf = logreg.fit(X_train, y_train)\n",
    "print('Accuracy of Lasso classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Lasso classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "6rlNHdAHenUK",
    "outputId": "59ada522-19d8-4ff3-cf99-7d3e1e2c16b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBClassifier on training set: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBClassifier on test set: 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.96      2564\n",
      "          1       0.96      0.98      0.97      2636\n",
      "\n",
      "avg / total       0.97      0.97      0.97      5200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "clf = xgb.fit(X_train, y_train)\n",
    "print('Accuracy of XGBClassifier on training set: {:.2f}'\n",
    "     .format(xgb.score(X_train, y_train)))\n",
    "print('Accuracy of XGBClassifier on test set: {:.2f}'\n",
    "     .format(xgb.score(X_test, y_test)))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9Hb9diBp6-D_"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=3, probability=True)\n",
    "clf = svc .fit(X_train, y_train)\n",
    "print('Accuracy of svc  on training set: {:.2f}'\n",
    "     .format(svc.score(X_train, y_train)))\n",
    "print('Accuracy of svc  on test set: {:.2f}'\n",
    "     .format(svc.score(X_test, y_test)))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9pp_EfugpdNi",
    "outputId": "082c9d81-7d81-4938-e3d9-0a622b45e294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BaggingClassifier on training set: 1.00\n",
      "Accuracy of BaggingClassifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier      # Bagging 每個模型都不錯 做 Voting/Avg 找出最好的 或是給權重  ex:RF\n",
    "from sklearn.ensemble import AdaBoostClassifier     # Boosting 給數個弱學習器 適合不夠強的模型\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=clf, n_estimators=100,max_samples=0.5, max_features=0.5)\n",
    "clf1 = bag.fit(X_train, y_train)\n",
    "print('Accuracy of BaggingClassifier on training set: {:.2f}'\n",
    "     .format(bag.score(X_train,  y_train)))\n",
    "print('Accuracy of BaggingClassifier on test set: {:.2f}'\n",
    "     .format(bag.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CC3xyBErpdRg",
    "outputId": "04f75a3e-109b-418a-957c-b69a212383ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LGBMClassifier on training set: 1.00\n",
      "Accuracy of LGBMClassifier on test set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2564\n",
      "           1       0.98      0.98      0.98      2636\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5200\n",
      "   macro avg       0.98      0.98      0.98      5200\n",
      "weighted avg       0.98      0.98      0.98      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(boosting_type= 'gbdt', objective = 'binary')\n",
    "clf = lgbm.fit(X_train, y_train)\n",
    "print('Accuracy of LGBMClassifier on training set: {:.2f}'\n",
    "     .format(lgbm.score(X_train, y_train)))\n",
    "print('Accuracy of LGBMClassifier on test set: {:.2f}'\n",
    "     .format(lgbm.score(X_test, y_test)))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "d4MmfGcJpdT0",
    "outputId": "de9e0064-ed8f-4d56-f14f-5731a56d684d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VotingClassifier on training set: 1.00\n",
      "Accuracy of VotingClassifier on test set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      2564\n",
      "           1       0.98      0.99      0.98      2636\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5200\n",
      "   macro avg       0.98      0.98      0.98      5200\n",
      "weighted avg       0.98      0.98      0.98      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier      # Bagging 每個模型都不錯 做 Voting/Avg 找出最好的 或是給權重  ex:RF\n",
    "from sklearn.ensemble import AdaBoostClassifier     # Boosting 給數個弱學習器 適合不夠強的模型\n",
    "\n",
    "#eclf1 = VotingClassifier(estimators=[('lr', lgbm), ('rf', rf), ('nb',xgb2), ('gb', gb), ('svc',svc), ('nn',nn)], voting='soft')\n",
    "eclf1 = VotingClassifier(estimators=[('logreg',logreg),('lgbm',lgbm)], voting='soft')\n",
    "#eclf1 = eclf1.fit(x_train, y_train)\n",
    "#score = eclf1.score(x_val, y_val)\n",
    "#cross_val_score(estimator=clf,X=x_val,y=y_val,cv=3)\n",
    "\n",
    "#bag = AdaBoostClassifier(base_estimator=eclf1, n_estimators=50)\n",
    "#bag = BaggingClassifier(base_estimator=eclf1, n_estimators=2,max_samples=0.5, max_features=0.5)\n",
    "\n",
    "clf = eclf1.fit(X_train, y_train)\n",
    "print('Accuracy of VotingClassifier on training set: {:.2f}'\n",
    "     .format(eclf1.score(X_train, y_train)))\n",
    "print('Accuracy of VotingClassifier on test set: {:.2f}'\n",
    "     .format(eclf1.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "predictions = eclf1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "zVtoTNC3V-Z_",
    "outputId": "18aa54e3-3716-48d0-cfe5-1085ebd2319b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Majarity_Voting_AdaBoost on training set: 1.00\n",
      "Accuracy of Majarity_Voting_AdaBoost on test set: 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98      2564\n",
      "          1       0.98      0.99      0.98      2636\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will oom\n",
    "\n",
    "bag = AdaBoostClassifier(base_estimator=eclf1, n_estimators=50)\n",
    "\n",
    "clf2 = bag.fit(X_train, y_train)\n",
    "print('Accuracy of Majarity_Voting_AdaBoost on training set: {:.2f}'\n",
    "     .format(bag.score(X_train, y_train)))\n",
    "print('Accuracy of Majarity_Voting_AdaBoost on test set: {:.2f}'\n",
    "     .format(bag.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "predictions = clf2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "3ed9CijIgBmk",
    "outputId": "38a85bf0-5650-41a4-bc38-8d59a10eabc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Majarity_Voting_AdaBoost on training set: 1.00\n",
      "Accuracy of Majarity_Voting_AdaBoost on test set: 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98      2564\n",
      "          1       0.98      0.99      0.98      2636\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier \n",
    "\n",
    "\n",
    "bag2 = BaggingClassifier(base_estimator=eclf1, n_estimators=5)\n",
    "\n",
    "clf3 = bag2.fit(X_train, y_train)\n",
    "print('Accuracy of Majarity_Voting_AdaBoost on training set: {:.2f}'\n",
    "     .format(bag2.score(X_train, y_train)))\n",
    "print('Accuracy of Majarity_Voting_AdaBoost on test set: {:.2f}'\n",
    "     .format(bag2.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "predictions = clf3.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2548
    },
    "colab_type": "code",
    "id": "vDjrqG0UB-kI",
    "outputId": "be516d7b-3b0b-4dab-8d39-9b4b58ad5350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "exception calling callback for <Future at 0x7fa4305abef0 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/reusable_executor.py\", line 151, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 1022, in submit\n",
      "    raise self._flags.broken\n",
      "sklearn.externals.joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-54dcc23d41a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbag2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mgrid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 151\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV ,  RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "params = {\n",
    "                 'n_estimators':[5,15,25,30,50]\n",
    "             # 'max_depth': [100,35,25],\n",
    "              #'learning_rate': [0.01,0.15,0.1],\n",
    "              #'feature_fraction': [0.6, 0.95],\n",
    "              #'bagging_fraction': [0.6, 0.7],\n",
    "              #'bagging_freq': [2, 8],\n",
    "              #'lambda_l1': [0,0.4],\n",
    "              #'lambda_l2': [0, 10,40],\n",
    "              #'cat_smooth': [1, 35]\n",
    "          \n",
    "}\n",
    "\n",
    "bag2 = BaggingClassifier(base_estimator=eclf1, n_estimators=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=bag2, param_grid=params, cv=5,verbose=1,n_jobs=-1)\n",
    "grid1 = grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameter set: %s ' % grid1.best_params_)\n",
    "\n",
    "\n",
    "print('Accuracy of LGBMClassifier on training set: {:.2f}'\n",
    "     .format(grid.score(X_train, y_train)))\n",
    "print('Accuracy of LGBMClassifier on test set: {:.2f}'\n",
    "     .format(grid.score(X_test, y_test)))\n",
    "\n",
    "predictions = grid1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "d2_NjMP7Yol9",
    "outputId": "fb8e7c15-2df3-41b7-a065-040f9dc872ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed: 22.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'n_estimators': 800} \n",
      "Accuracy of LGBMClassifier on training set: 1.00\n",
      "Accuracy of LGBMClassifier on test set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      2564\n",
      "           1       0.98      0.99      0.99      2636\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      5200\n",
      "   macro avg       0.98      0.98      0.98      5200\n",
      "weighted avg       0.98      0.98      0.98      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV ,  RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "params = {\n",
    "                 'n_estimators':[800,1600,1200]\n",
    "             # 'max_depth': [100,35,25],\n",
    "              #'learning_rate': [0.01,0.15,0.1],\n",
    "              #'feature_fraction': [0.6, 0.95],\n",
    "              #'bagging_fraction': [0.6, 0.7],\n",
    "              #'bagging_freq': [2, 8],\n",
    "              #'lambda_l1': [0,0.4],\n",
    "              #'lambda_l2': [0, 10,40],\n",
    "              #'cat_smooth': [1, 35]\n",
    "          \n",
    "}\n",
    "\n",
    "bag2 = BaggingClassifier(base_estimator=eclf1, n_estimators=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=lgbm, param_grid=params, cv=2,verbose=1,n_jobs=-1)\n",
    "grid1 = grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameter set: %s ' % grid1.best_params_)\n",
    "\n",
    "\n",
    "print('Accuracy of LGBMClassifier on training set: {:.2f}'\n",
    "     .format(grid.score(X_train, y_train)))\n",
    "print('Accuracy of LGBMClassifier on test set: {:.2f}'\n",
    "     .format(grid.score(X_test, y_test)))\n",
    "\n",
    "predictions = grid1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JSgWsEkFQ7ro"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E8mOITX1Q7tt",
    "outputId": "698faed2-9477-41fe-8ad7-c0922510c336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_fake_news.csv  train_fake_news.csv  人工智慧期末.ipynb\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/content/drive/My Drive/Colab/人工智慧期末')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yotUuOSpQ7wV",
    "outputId": "3687cc8a-67eb-4f28-8352-0e272309476c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#1: unreliable\n",
    "#0: reliable\n",
    "train=pd.read_csv('train_fake_news.csv')\n",
    "test=pd.read_csv('test_fake_news.csv')\n",
    "test['label']='t'\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#data prep\n",
    "test=test.fillna(' ')\n",
    "train=train.fillna(' ')\n",
    "test['total']=test['title']+' '+test['author']+test['text']\n",
    "train['total']=train['title']+' '+train['author']+train['text']\n",
    "targets = train['label'].values\n",
    "df5= train['total'].astype(str)\n",
    "df5 = df5.values.tolist()\n",
    "df5 = [\"\".join(map(str, lst)) for lst in df5]  # 變成 一個一個的 ROW\n",
    "df6 = df5\n",
    "type(df6[0])\n",
    "import re #匯入Regular Expression模組\n",
    "stop = stopwords.words('english')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "result = list()\n",
    "for line in df6:    \n",
    "\n",
    "    line = re.sub('<[^>]*>', '', line)\n",
    "    line1 = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                          line.lower())\n",
    "    \n",
    "    line = re.sub('[\\W]+', ' ', line.lower()) \\\n",
    "                   + ' '.join(line1).replace('-', '')\n",
    "    #line = re.sub(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',' ', line) \n",
    "        \n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stop) + r')\\b\\s*')    # 去除停用字但可以分成一句一句\n",
    "    line = pattern.sub('', line)\n",
    "    \n",
    "    \n",
    "#    line = re.sub(r'[^\\u4e00-\\u9fa5p]',' ', line) \n",
    "#    line = re.sub(u\"\\\\(.*?\\\\)|\\\\{.*?}|\\\\[.*?]\", \" \", line)   # 去除() {} [] 中的值\n",
    "#    line = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', line)           # 去除 重複的值\n",
    "#    line = re.sub(r'[^\\u4e00-\\u9fa5p]',' ', line)            # 去除非中文的值\n",
    "    \n",
    "    result.append(line)  \n",
    "token = Tokenizer(num_words=200000)\n",
    "token.fit_on_texts(result)\n",
    "x_train_seq = token.texts_to_sequences(result)\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen=1000,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cp63rJfTQ7yz"
   },
   "outputs": [],
   "source": [
    "'''from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GRU\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    "from keras.models import Model \n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers.convolutional import Conv2D, Conv3D\n",
    "from keras.layers import Add,Flatten,Concatenate, GlobalAveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "S_inputs = Input(shape=(None, ))  # 輸入層\n",
    "embeddings1 = Embedding(output_dim=512,input_dim=200000,input_length=1000)(S_inputs)   \n",
    "\n",
    "x = Conv1D(512, 1, strides=1, padding='valid', activation='relu')(embeddings1) \n",
    "x = Conv1D(filters=128, kernel_size=3, strides=1,padding='valid', activation='relu')(x)\n",
    "x = Conv1D(512, 1, strides=1, padding='valid', activation='relu')(x) \n",
    "x = Conv1D(1, 1,strides=1, padding='valid', activation='sigmoid')(x) \n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "model = Model(inputs=S_inputs, outputs=x)\n",
    "model.summary()'''\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GRU\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim=200000, \n",
    "                    input_length=1000))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.add(keras.layers.core.Masking(mask_value=0., input_shape=(max_lenth, max_features)))\n",
    "model.add(Bidirectional(GRU(units=16,activation='selu',kernel_initializer='orthogonal', recurrent_initializer='orthogonal',\n",
    "              bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01), recurrent_regularizer=regularizers.l2(0.01),\n",
    "              bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,\n",
    "              bias_constraint=None, dropout=0.5, recurrent_dropout=0.0, implementation=1, return_sequences=True,#多层时需设置为true\n",
    "              return_state=False, go_backwards=False, stateful=False, unroll=False),merge_mode='concat'))   #input_shape=(max_lenth, max_features),\n",
    "model.add(Bidirectional(GRU(units=16,activation='selu',kernel_initializer='orthogonal', recurrent_initializer='orthogonal',\n",
    "              bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01), recurrent_regularizer=regularizers.l2(0.01),\n",
    "              bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,\n",
    "              bias_constraint=None, dropout=0.5, recurrent_dropout=0.0, implementation=1, return_sequences=True,\n",
    "              return_state=False, go_backwards=False, stateful=False, unroll=False),merge_mode='concat'))   #input_shape=(max_lenth, max_features),\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AttentionWithContext())\n",
    "model.add(Dense(1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(keras.layers.core.Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IbvuI6eKcsCM"
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "iR1c4i0tYnwr",
    "outputId": "f27271af-00b9-448c-e6fb-aad73d4507a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18720 samples, validate on 2080 samples\n",
      "Epoch 1/10\n",
      "18720/18720 [==============================] - 417s 22ms/step - loss: 0.9835 - acc: 0.9379 - val_loss: 0.6786 - val_acc: 0.9596\n",
      "Epoch 2/10\n",
      "18720/18720 [==============================] - 406s 22ms/step - loss: 0.5667 - acc: 0.9795 - val_loss: 0.4952 - val_acc: 0.9490\n",
      "Epoch 3/10\n",
      "18720/18720 [==============================] - 405s 22ms/step - loss: 0.3971 - acc: 0.9889 - val_loss: 0.4742 - val_acc: 0.9466\n",
      "Epoch 4/10\n",
      "18720/18720 [==============================] - 403s 22ms/step - loss: 0.3172 - acc: 0.9923 - val_loss: 0.4956 - val_acc: 0.9563\n",
      "Epoch 5/10\n",
      "18720/18720 [==============================] - 401s 21ms/step - loss: 0.2772 - acc: 0.9939 - val_loss: 0.5364 - val_acc: 0.9534\n",
      "Epoch 6/10\n",
      "18720/18720 [==============================] - 397s 21ms/step - loss: 0.2516 - acc: 0.9951 - val_loss: 0.5595 - val_acc: 0.9611\n",
      "Epoch 7/10\n",
      "18720/18720 [==============================] - 397s 21ms/step - loss: 0.2329 - acc: 0.9967 - val_loss: 0.6415 - val_acc: 0.8082\n",
      "Epoch 8/10\n",
      "18720/18720 [==============================] - 395s 21ms/step - loss: 0.2178 - acc: 0.9975 - val_loss: 0.6455 - val_acc: 0.8774\n",
      "Epoch 9/10\n",
      "18720/18720 [==============================] - 394s 21ms/step - loss: 0.2055 - acc: 0.9974 - val_loss: 0.6438 - val_acc: 0.5452\n",
      "Epoch 10/10\n",
      "18720/18720 [==============================] - 397s 21ms/step - loss: 0.1938 - acc: 0.9978 - val_loss: 0.6311 - val_acc: 0.9543\n"
     ]
    }
   ],
   "source": [
    "#opt = keras.optimizers.adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  #使用compile對訊連模型進行設定,損失函數,在深度學習使用cross_entropy交叉熵\n",
    "              optimizer= 'adam',  #設定訓練時的最優化方法,用adam,可以讓訓練更快收斂,提高準確率\n",
    "              metrics=['accuracy']) #設定\n",
    "\n",
    "model.fit(x_train, targets, batch_size=256, epochs=10, verbose=1,validation_split=0.1)\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7v9pnTqymnMy"
   },
   "outputs": [],
   "source": [
    "model.save('my_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IdgY6kNkYnyz"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    " \n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    " \n",
    " \n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    " \n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    " \n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    " \n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    " \n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    " \n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    " \n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    " \n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    " \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    " \n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    " \n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    " \n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    " \n",
    "        a = K.exp(ait)\n",
    " \n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    " \n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    " \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XY7ESKfVYn1Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ozvu6REYQ709"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "class Position_Embedding(Layer):\n",
    "    \n",
    "    def __init__(self, size=None, mode='sum', **kwargs):\n",
    "        self.size = size #必须为偶数\n",
    "        self.mode = mode\n",
    "        super(Position_Embedding, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        if (self.size == None) or (self.mode == 'sum'):\n",
    "            self.size = int(x.shape[-1])\n",
    "        batch_size,seq_len = K.shape(x)[0],K.shape(x)[1]\n",
    "        position_j = 1. / K.pow(10000., \\\n",
    "                                 2 * K.arange(self.size / 2, dtype='float32' \\\n",
    "                               ) / self.size)\n",
    "        position_j = K.expand_dims(position_j, 0)\n",
    "        position_i = K.cumsum(K.ones_like(x[:,:,0]), 1)-1 #K.arange不支持变长，只好用这种方法生成\n",
    "        position_i = K.expand_dims(position_i, 2)\n",
    "        position_ij = K.dot(position_i, position_j)\n",
    "        position_ij = K.concatenate([K.cos(position_ij), K.sin(position_ij)], 2)\n",
    "        if self.mode == 'sum':\n",
    "            return position_ij + x\n",
    "        elif self.mode == 'concat':\n",
    "            return K.concatenate([position_ij, x], 2)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.mode == 'sum':\n",
    "            return input_shape\n",
    "        elif self.mode == 'concat':\n",
    "            return (input_shape[0], input_shape[1], input_shape[2]+self.size)\n",
    "\n",
    "\n",
    "class SelfAttention(Layer):\n",
    "\n",
    "    def __init__(self, nb_head, size_per_head, **kwargs):\n",
    "        self.nb_head = nb_head\n",
    "        self.size_per_head = size_per_head\n",
    "        self.output_dim = nb_head*size_per_head\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.WQ = self.add_weight(name='WQ', \n",
    "                                  shape=(input_shape[0][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WK = self.add_weight(name='WK', \n",
    "                                  shape=(input_shape[1][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WV = self.add_weight(name='WV', \n",
    "                                  shape=(input_shape[2][-1], self.output_dim),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "        \n",
    "    def Mask(self, inputs, seq_len, mode='mul'):\n",
    "        if seq_len == None:\n",
    "            return inputs\n",
    "        else:\n",
    "            mask = K.one_hot(seq_len[:,0], K.shape(inputs)[1])\n",
    "            mask = 1 - K.cumsum(mask, 1)\n",
    "            for _ in range(len(inputs.shape)-2):\n",
    "                mask = K.expand_dims(mask, 2)\n",
    "            if mode == 'mul':\n",
    "                return inputs * mask\n",
    "            if mode == 'add':\n",
    "                return inputs - (1 - mask) * 1e12\n",
    "                \n",
    "    def call(self, x):\n",
    "        #如果只传入Q_seq,K_seq,V_seq，那么就不做Mask\n",
    "        #如果同时传入Q_seq,K_seq,V_seq,Q_len,V_len，那么对多余部分做Mask\n",
    "        if len(x) == 3:\n",
    "            Q_seq,K_seq,V_seq = x\n",
    "            Q_len,V_len = None,None\n",
    "        elif len(x) == 5:\n",
    "            Q_seq,K_seq,V_seq,Q_len,V_len = x\n",
    "        #对Q、K、V做线性变换\n",
    "        Q_seq = K.dot(Q_seq, self.WQ)\n",
    "        Q_seq = K.reshape(Q_seq, (-1, K.shape(Q_seq)[1], self.nb_head, self.size_per_head))\n",
    "        Q_seq = K.permute_dimensions(Q_seq, (0,2,1,3))\n",
    "        K_seq = K.dot(K_seq, self.WK)\n",
    "        K_seq = K.reshape(K_seq, (-1, K.shape(K_seq)[1], self.nb_head, self.size_per_head))\n",
    "        K_seq = K.permute_dimensions(K_seq, (0,2,1,3))\n",
    "        V_seq = K.dot(V_seq, self.WV)\n",
    "        V_seq = K.reshape(V_seq, (-1, K.shape(V_seq)[1], self.nb_head, self.size_per_head))\n",
    "        V_seq = K.permute_dimensions(V_seq, (0,2,1,3))\n",
    "        #计算内积，然后mask，然后softmax\n",
    "        A = K.batch_dot(Q_seq, K_seq, axes=[3,3]) / self.size_per_head**0.5\n",
    "        A = K.permute_dimensions(A, (0,3,2,1))\n",
    "        A = self.Mask(A, V_len, 'add')\n",
    "        A = K.permute_dimensions(A, (0,3,2,1))    \n",
    "        A = K.softmax(A)\n",
    "        #输出并mask\n",
    "        O_seq = K.batch_dot(A, V_seq, axes=[3,2])\n",
    "        O_seq = K.permute_dimensions(O_seq, (0,2,1,3))\n",
    "        O_seq = K.reshape(O_seq, (-1, K.shape(O_seq)[1], self.output_dim))\n",
    "        O_seq = self.Mask(O_seq, Q_len, 'mul')\n",
    "        return O_seq\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jgq6A7fFQ74E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "人工智慧期末.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
